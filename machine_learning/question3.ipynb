{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-3. Problem Statement\n",
    "\n",
    "Imagine you have a dataset where you have different categories of data, \n",
    "\n",
    "Now you need to find the most similar data to the given data by using any 4 different\n",
    "similarity algorithms. \n",
    "\n",
    "Now you have to build a model which can find the most similar\n",
    "data to the given data.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Info\n",
    "\n",
    "Link : https://www.kaggle.com/datasets/rmisra/news-category-dataset\n",
    "\n",
    "The file contains 210,294 records between 2012 and 2022. Each json record contains the following attributes:\n",
    "\n",
    "- category: Category article belongs to\n",
    "\n",
    "- headline: Headline of the article\n",
    "\n",
    "- authors: Person authored the article\n",
    "\n",
    "- link: Link to the post\n",
    "\n",
    "- short_description: Short description of the article\n",
    "\n",
    "- date: Date the article was published"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Trailing data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m file_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mNews_Category_Dataset_v3.json\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_json(file_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/pandas/io/json/_json.py:784\u001b[0m, in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    782\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\n\u001b[1;32m    783\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 784\u001b[0m     \u001b[39mreturn\u001b[39;00m json_reader\u001b[39m.\u001b[39;49mread()\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/pandas/io/json/_json.py:975\u001b[0m, in \u001b[0;36mJsonReader.read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m         obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_object_parser(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_lines(data_lines))\n\u001b[1;32m    974\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 975\u001b[0m     obj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_object_parser(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata)\n\u001b[1;32m    976\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype_backend \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[1;32m    977\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mconvert_dtypes(\n\u001b[1;32m    978\u001b[0m         infer_objects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype_backend\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype_backend\n\u001b[1;32m    979\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/pandas/io/json/_json.py:1001\u001b[0m, in \u001b[0;36mJsonReader._get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m    999\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1000\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mframe\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 1001\u001b[0m     obj \u001b[39m=\u001b[39m FrameParser(json, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39;49mparse()\n\u001b[1;32m   1003\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mseries\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1004\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(dtype, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/pandas/io/json/_json.py:1134\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mparse\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m-> 1134\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_parse()\n\u001b[1;32m   1136\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1137\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/pandas/io/json/_json.py:1320\u001b[0m, in \u001b[0;36mFrameParser._parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1316\u001b[0m orient \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39morient\n\u001b[1;32m   1318\u001b[0m \u001b[39mif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1319\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj \u001b[39m=\u001b[39m DataFrame(\n\u001b[0;32m-> 1320\u001b[0m         loads(json, precise_float\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecise_float), dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m     )\n\u001b[1;32m   1322\u001b[0m \u001b[39melif\u001b[39;00m orient \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msplit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1323\u001b[0m     decoded \u001b[39m=\u001b[39m {\n\u001b[1;32m   1324\u001b[0m         \u001b[39mstr\u001b[39m(k): v\n\u001b[1;32m   1325\u001b[0m         \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m loads(json, precise_float\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecise_float)\u001b[39m.\u001b[39mitems()\n\u001b[1;32m   1326\u001b[0m     }\n",
      "\u001b[0;31mValueError\u001b[0m: Trailing data"
     ]
    }
   ],
   "source": [
    "file_path = \"News_Category_Dataset_v3.json\"\n",
    "df = pd.read_json(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            obj = json.loads(line)\n",
    "            data.append(obj)\n",
    "        except json.JSONDecodeError:\n",
    "            pass\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>link</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>headline</th>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>short_description</th>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>authors</th>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>2022-09-22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0   \n",
       "link               https://www.huffpost.com/entry/covid-boosters-...  \\\n",
       "headline           Over 4 Million Americans Roll Up Sleeves For O...   \n",
       "category                                                   U.S. NEWS   \n",
       "short_description  Health experts said it is too early to predict...   \n",
       "authors                                         Carla K. Johnson, AP   \n",
       "date                                                      2022-09-23   \n",
       "\n",
       "                                                                   1   \n",
       "link               https://www.huffpost.com/entry/american-airlin...  \\\n",
       "headline           American Airlines Flyer Charged, Banned For Li...   \n",
       "category                                                   U.S. NEWS   \n",
       "short_description  He was subdued by passengers and crew when he ...   \n",
       "authors                                               Mary Papenfuss   \n",
       "date                                                      2022-09-23   \n",
       "\n",
       "                                                                   2   \n",
       "link               https://www.huffpost.com/entry/funniest-tweets...  \\\n",
       "headline           23 Of The Funniest Tweets About Cats And Dogs ...   \n",
       "category                                                      COMEDY   \n",
       "short_description  \"Until you have a dog you don't understand wha...   \n",
       "authors                                                Elyse Wanshel   \n",
       "date                                                      2022-09-23   \n",
       "\n",
       "                                                                   3   \n",
       "link               https://www.huffpost.com/entry/funniest-parent...  \\\n",
       "headline           The Funniest Tweets From Parents This Week (Se...   \n",
       "category                                                   PARENTING   \n",
       "short_description  \"Accidentally put grown-up toothpaste on my to...   \n",
       "authors                                             Caroline Bologna   \n",
       "date                                                      2022-09-23   \n",
       "\n",
       "                                                                   4  \n",
       "link               https://www.huffpost.com/entry/amy-cooper-lose...  \n",
       "headline           Woman Who Called Cops On Black Bird-Watcher Lo...  \n",
       "category                                                   U.S. NEWS  \n",
       "short_description  Amy Cooper accused investment firm Franklin Te...  \n",
       "authors                                               Nina Golgowski  \n",
       "date                                                      2022-09-22  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'headline', 'category', 'short_description', 'authors', 'date'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'https://www.huffpost.com/entry/fiona-threatens-to-become-category-4-storm-headed-to-bermuda_n_632ad1cae4b07198f0143244'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m given_data \u001b[39m=\u001b[39m df\u001b[39m.\u001b[39miloc[\u001b[39m12\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[39m# Calculate cosine similarity between the given data and all other data points\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m similarity_scores \u001b[39m=\u001b[39m cosine_similarity(given_data, df)\n\u001b[1;32m      6\u001b[0m \u001b[39m# Sort the similarity scores in descending order\u001b[39;00m\n\u001b[1;32m      7\u001b[0m sorted_indices \u001b[39m=\u001b[39m similarity_scores\u001b[39m.\u001b[39margsort()[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:1393\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1359\u001b[0m \n\u001b[1;32m   1360\u001b[0m \u001b[39mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[39m    Returns the cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1390\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1391\u001b[0m \u001b[39m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1393\u001b[0m X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(X, Y)\n\u001b[1;32m   1395\u001b[0m X_normalized \u001b[39m=\u001b[39m normalize(X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1396\u001b[0m \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:155\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m     X \u001b[39m=\u001b[39m Y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    147\u001b[0m         X,\n\u001b[1;32m    148\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    152\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    156\u001b[0m         X,\n\u001b[1;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    158\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    159\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    160\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    164\u001b[0m         Y,\n\u001b[1;32m    165\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'https://www.huffpost.com/entry/fiona-threatens-to-become-category-4-storm-headed-to-bermuda_n_632ad1cae4b07198f0143244'"
     ]
    }
   ],
   "source": [
    "given_data = df.iloc[12]\n",
    "\n",
    "# Calculate cosine similarity between the given data and all other data points\n",
    "similarity_scores = cosine_similarity(given_data, df)\n",
    "\n",
    "# Sort the similarity scores in descending order\n",
    "sorted_indices = similarity_scores.argsort()[::-1]\n",
    "\n",
    "# Retrieve the top-k most similar data points\n",
    "top_k_indices = sorted_indices[:k]\n",
    "most_similar_data = df[top_k_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar headline: If your freezer is overflowing, or you're tired of carrying around ice packs and bottles of pumped milk, this option could be for you.\n"
     ]
    }
   ],
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the text data\n",
    "tfidf_matrix = vectorizer.fit_transform(df['short_description'])\n",
    "\n",
    "# Select any headline\n",
    "target_headline = df['short_description'].iloc[123]\n",
    "\n",
    "# Transform the target headline\n",
    "target_tfidf = vectorizer.transform([target_headline])\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity_scores = cosine_similarity(tfidf_matrix, target_tfidf).ravel()\n",
    "\n",
    "# Find the most similar headline\n",
    "most_similar_index = similarity_scores.argmax()\n",
    "most_similar_headline = df.loc[most_similar_index, 'short_description']\n",
    "\n",
    "print(\"Most similar headline:\", most_similar_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_similar_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for preprocessing the text\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove special characters and symbols\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text)\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Join the tokens back into a single string\n",
    "    processed_text = \" \".join(tokens)\n",
    "    \n",
    "    return processed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the headlines\n",
    "df['processed_headline'] = df['headline'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link</th>\n",
       "      <th>headline</th>\n",
       "      <th>category</th>\n",
       "      <th>short_description</th>\n",
       "      <th>authors</th>\n",
       "      <th>date</th>\n",
       "      <th>processed_headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffpost.com/entry/covid-boosters-...</td>\n",
       "      <td>Over 4 Million Americans Roll Up Sleeves For O...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Health experts said it is too early to predict...</td>\n",
       "      <td>Carla K. Johnson, AP</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>4 million americans roll sleeves omicron targe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffpost.com/entry/american-airlin...</td>\n",
       "      <td>American Airlines Flyer Charged, Banned For Li...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>He was subdued by passengers and crew when he ...</td>\n",
       "      <td>Mary Papenfuss</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>american airlines flyer charged banned life pu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-tweets...</td>\n",
       "      <td>23 Of The Funniest Tweets About Cats And Dogs ...</td>\n",
       "      <td>COMEDY</td>\n",
       "      <td>\"Until you have a dog you don't understand wha...</td>\n",
       "      <td>Elyse Wanshel</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>23 funniest tweets cats dogs week sept 17 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.huffpost.com/entry/funniest-parent...</td>\n",
       "      <td>The Funniest Tweets From Parents This Week (Se...</td>\n",
       "      <td>PARENTING</td>\n",
       "      <td>\"Accidentally put grown-up toothpaste on my to...</td>\n",
       "      <td>Caroline Bologna</td>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>funniest tweets parents week sept 17 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffpost.com/entry/amy-cooper-lose...</td>\n",
       "      <td>Woman Who Called Cops On Black Bird-Watcher Lo...</td>\n",
       "      <td>U.S. NEWS</td>\n",
       "      <td>Amy Cooper accused investment firm Franklin Te...</td>\n",
       "      <td>Nina Golgowski</td>\n",
       "      <td>2022-09-22</td>\n",
       "      <td>woman called cops black bird watcher loses law...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                link   \n",
       "0  https://www.huffpost.com/entry/covid-boosters-...  \\\n",
       "1  https://www.huffpost.com/entry/american-airlin...   \n",
       "2  https://www.huffpost.com/entry/funniest-tweets...   \n",
       "3  https://www.huffpost.com/entry/funniest-parent...   \n",
       "4  https://www.huffpost.com/entry/amy-cooper-lose...   \n",
       "\n",
       "                                            headline   category   \n",
       "0  Over 4 Million Americans Roll Up Sleeves For O...  U.S. NEWS  \\\n",
       "1  American Airlines Flyer Charged, Banned For Li...  U.S. NEWS   \n",
       "2  23 Of The Funniest Tweets About Cats And Dogs ...     COMEDY   \n",
       "3  The Funniest Tweets From Parents This Week (Se...  PARENTING   \n",
       "4  Woman Who Called Cops On Black Bird-Watcher Lo...  U.S. NEWS   \n",
       "\n",
       "                                   short_description               authors   \n",
       "0  Health experts said it is too early to predict...  Carla K. Johnson, AP  \\\n",
       "1  He was subdued by passengers and crew when he ...        Mary Papenfuss   \n",
       "2  \"Until you have a dog you don't understand wha...         Elyse Wanshel   \n",
       "3  \"Accidentally put grown-up toothpaste on my to...      Caroline Bologna   \n",
       "4  Amy Cooper accused investment firm Franklin Te...        Nina Golgowski   \n",
       "\n",
       "         date                                 processed_headline  \n",
       "0  2022-09-23  4 million americans roll sleeves omicron targe...  \n",
       "1  2022-09-23  american airlines flyer charged banned life pu...  \n",
       "2  2022-09-23       23 funniest tweets cats dogs week sept 17 23  \n",
       "3  2022-09-23            funniest tweets parents week sept 17 23  \n",
       "4  2022-09-22  woman called cops black bird watcher loses law...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modified Dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Michigan Secretary of State Worried About ‘Violence And Disruption’ Going Into Midterms'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['headline'].iloc[102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tinku/anaconda3/envs/assesment/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:2025: DataConversionWarning: Data was converted to boolean for metric jaccard\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'michigan secretary state worried violence disruption going midterms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m target_headline \u001b[39m=\u001b[39m preprocess_text(df[\u001b[39m'\u001b[39m\u001b[39mheadline\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m102\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[39m# Calculate Jaccard similarity\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m similarity_scores \u001b[39m=\u001b[39m pairwise_distances(df[\u001b[39m'\u001b[39;49m\u001b[39mprocessed_headline\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mreshape(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m),\n\u001b[1;32m      6\u001b[0m                                        [target_headline],\n\u001b[1;32m      7\u001b[0m                                        metric\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mjaccard\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39mravel()\n\u001b[1;32m      9\u001b[0m \u001b[39m# Find the most similar headline\u001b[39;00m\n\u001b[1;32m     10\u001b[0m most_similar_index \u001b[39m=\u001b[39m similarity_scores\u001b[39m.\u001b[39margmin()\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:2027\u001b[0m, in \u001b[0;36mpairwise_distances\u001b[0;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[1;32m   2024\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mData was converted to boolean for metric \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m metric\n\u001b[1;32m   2025\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg, DataConversionWarning)\n\u001b[0;32m-> 2027\u001b[0m X, Y \u001b[39m=\u001b[39m check_pairwise_arrays(\n\u001b[1;32m   2028\u001b[0m     X, Y, dtype\u001b[39m=\u001b[39;49mdtype, force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite\n\u001b[1;32m   2029\u001b[0m )\n\u001b[1;32m   2031\u001b[0m \u001b[39m# precompute data-derived metric params\u001b[39;00m\n\u001b[1;32m   2032\u001b[0m params \u001b[39m=\u001b[39m _precompute_metric_params(X, Y, metric\u001b[39m=\u001b[39mmetric, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/sklearn/metrics/pairwise.py:163\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, copy)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    156\u001b[0m         X,\n\u001b[1;32m    157\u001b[0m         accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    161\u001b[0m         estimator\u001b[39m=\u001b[39mestimator,\n\u001b[1;32m    162\u001b[0m     )\n\u001b[0;32m--> 163\u001b[0m     Y \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    164\u001b[0m         Y,\n\u001b[1;32m    165\u001b[0m         accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    166\u001b[0m         dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    167\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    168\u001b[0m         force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    169\u001b[0m         estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    172\u001b[0m \u001b[39mif\u001b[39;00m precomputed:\n\u001b[1;32m    173\u001b[0m     \u001b[39mif\u001b[39;00m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m Y\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/sklearn/utils/validation.py:879\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    877\u001b[0m         array \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(array, dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 879\u001b[0m         array \u001b[39m=\u001b[39m _asarray_with_order(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype, xp\u001b[39m=\u001b[39;49mxp)\n\u001b[1;32m    880\u001b[0m \u001b[39mexcept\u001b[39;00m ComplexWarning \u001b[39mas\u001b[39;00m complex_warning:\n\u001b[1;32m    881\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    882\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mComplex data not supported\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    883\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mcomplex_warning\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/assesment/lib/python3.9/site-packages/sklearn/utils/_array_api.py:185\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[1;32m    182\u001b[0m     xp, _ \u001b[39m=\u001b[39m get_namespace(array)\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m xp\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39min\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mnumpy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mnumpy.array_api\u001b[39m\u001b[39m\"\u001b[39m}:\n\u001b[1;32m    184\u001b[0m     \u001b[39m# Use NumPy API to support order\u001b[39;00m\n\u001b[0;32m--> 185\u001b[0m     array \u001b[39m=\u001b[39m numpy\u001b[39m.\u001b[39;49masarray(array, order\u001b[39m=\u001b[39;49morder, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    186\u001b[0m     \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39masarray(array, copy\u001b[39m=\u001b[39mcopy)\n\u001b[1;32m    187\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'michigan secretary state worried violence disruption going midterms'"
     ]
    }
   ],
   "source": [
    "# Select any headline\n",
    "target_headline = preprocess_text(df['headline'].iloc[102])\n",
    "\n",
    "# Calculate Jaccard similarity\n",
    "similarity_scores = pairwise_distances(df['processed_headline'].values.reshape(-1, 1),\n",
    "                                       [target_headline],\n",
    "                                       metric='jaccard').ravel()\n",
    "\n",
    "# Find the most similar headline\n",
    "most_similar_index = similarity_scores.argmin()\n",
    "most_similar_headline = df.loc[most_similar_index, 'headline']\n",
    "\n",
    "print(\"Most similar headline:\", most_similar_headline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assesment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
